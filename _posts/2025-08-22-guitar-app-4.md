---
layout: post
title: "기타 연주 앱 프로젝트 - 기타 사운드 분류 로직 구현하기 (2)"
date: 2025-08-22
tags: [Flutter, Audio Engineering, iOS, Android, AI, TFLite, YAMNet]
read_time: 15
subtitle: "YAMNet 모델로 실시간 온디바이스 기타 사운드 분류 로직을 구현해봅니다."
sgst_post: ["2025-04-30-guitar-app-3.md"]
---

## 개요

이 포스트는 [이전 포스트](https://dc143cdev.github.io/guitar-app-3/)에서 소개한 기타 사운드 분류 로직을 머신러닝 기반 분류기로 업그레이드하는 과정을 다룹니다.

**기타 사운드 분류기**에 대한 개념적 설명과 개발 동기에 대해서는 이전 포스트에서 상세히 다루었으니, 본 포스트에서는 **YAMNet** 모델을 플러터 앱에 온디바이스 형태로 탑재하고, 실시간 기타 사운드 분류 로직을 구현하는 과정을 주로 다루겠습니다.


## YAMNet이 뭔가요?

[Kaggle 모델 소개 페이지](https://www.kaggle.com/models/google/yamnet)